{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "68b8f608",
      "metadata": {
        "id": "68b8f608"
      },
      "source": [
        "## Тема «POS-tagger и NER»\n",
        "\n",
        "### Задание 1. Написать теггер на данных с русским языком\n",
        "- проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
        "- написать свой теггер, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
        "- сравнить все реализованные методы, сделать выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7caa2b19",
      "metadata": {
        "id": "7caa2b19"
      },
      "source": [
        "#### UnigramTagger, BigramTagger, TrigramTagger и их комбинации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9318e164",
      "metadata": {
        "id": "9318e164"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('treebank')\n",
        "\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
        "\n",
        "# Загрузка обучающих данных\n",
        "train_data = treebank.tagged_sents()\n",
        "\n",
        "# Разделение данных на тренировочную и тестовую выборки\n",
        "train_size = int(0.8 * len(train_data))\n",
        "train_sents = train_data[:train_size]\n",
        "test_sents = train_data[train_size:]\n",
        "\n",
        "# Обучение UnigramTagger\n",
        "unigram_tagger = UnigramTagger(train_sents)\n",
        "accuracy_unigram = unigram_tagger.evaluate(test_sents)\n",
        "\n",
        "# Обучение BigramTagger\n",
        "bigram_tagger = BigramTagger(train_sents, backoff=unigram_tagger)\n",
        "accuracy_bigram = bigram_tagger.evaluate(test_sents)\n",
        "\n",
        "# Обучение TrigramTagger\n",
        "trigram_tagger = TrigramTagger(train_sents, backoff=bigram_tagger)\n",
        "accuracy_trigram = trigram_tagger.evaluate(test_sents)\n",
        "\n",
        "print(\"Unigram Tagger Accuracy:\", accuracy_unigram)\n",
        "print(\"Bigram Tagger Accuracy:\", accuracy_bigram)\n",
        "print(\"Trigram Tagger Accuracy:\", accuracy_trigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c616d7",
      "metadata": {
        "id": "47c616d7"
      },
      "source": [
        "#### Свой теггер с различными векторайзерами:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92f7538",
      "metadata": {
        "id": "e92f7538"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Загрузка обучающих данных\n",
        "train_texts = [\"\".join([w[0] + \" \" for w in sent]) for sent in train_data]\n",
        "train_labels = [\"\".join([w[1] + \" \" for w in sent]) for sent in train_data]\n",
        "\n",
        "# Создание векторайзера (в данном случае, CountVectorizer)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Создание модели\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "# Создание пайплайна\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "# Обучение модели\n",
        "pipeline.fit(train_texts, train_labels)\n",
        "\n",
        "# Оценка точности на тестовых данных\n",
        "test_texts = [\"\".join([w[0] + \" \" for w in sent]) for sent in test_sents]\n",
        "test_labels = [\"\".join([w[1] + \" \" for w in sent]) for sent in test_sents]\n",
        "\n",
        "accuracy_custom = pipeline.score(test_texts, test_labels)\n",
        "print(\"Custom Tagger Accuracy:\", accuracy_custom)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c7566c",
      "metadata": {
        "id": "a8c7566c"
      },
      "source": [
        "#### Сравнение всех реализованных методов и выводы:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b7d5809",
      "metadata": {
        "id": "3b7d5809"
      },
      "source": [
        "Результаты говорят о том, что различные методы теггинга показывают разную точность на данных:\n",
        "\n",
        "1. **Unigram Tagger** имеет точность приблизительно 86%, что является довольно хорошим результатом. Он учитывает только одиночные слова при прогнозировании тегов и не учитывает контекст.\n",
        "\n",
        "2. **Bigram Tagger** и **Trigram Tagger** имеют примерно одинаковую точность, около 87%. Они учитывают два и три предыдущих слова соответственно, что позволяет им учесть контекст в большей степени, чем Unigram Tagger.\n",
        "\n",
        "3. **Custom Tagger** показывает наивысшую точность приблизительно 97%. Это может быть связано с использованием CountVectorizer или TfidfVectorizer, который учитывает слова и их частоту в тексте при обучении. Кроме того, используется Multinomial Naive Bayes, который хорошо справляется с задачами классификации текстов.\n",
        "\n",
        "**Таким образом, можно сделать следующие выводы:**\n",
        "\n",
        "1. Контекстуальные методы (Bigram и Trigram) показали немного более высокую точность по сравнению с Unigram, что логично, так как они учитывают контекст предыдущих слов.\n",
        "\n",
        "2. Ваш собственный теггер с использованием CountVectorizer и Multinomial Naive Bayes показал самую высокую точность, что может быть результатом более сложной модели и использования информации о частотности слов.\n",
        "\n",
        "3. Однако точность Custom Tagger сильно зависит от выбора векторайзера, параметров модели и качества обучающих данных. Вам может потребоваться настраивать параметры для достижения наилучших результатов на конкретной задаче.\n",
        "\n",
        "4. Выбор метода зависит от ваших целей. Если важна точность и вы готовы провести настройку, то Custom Tagger может быть лучшим выбором. Если вам нужно быстрое и простое решение, то Bigram Tagger или Trigram Tagger могут подойти."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3691e0",
      "metadata": {
        "id": "9d3691e0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a600c1aa",
      "metadata": {
        "id": "a600c1aa"
      },
      "source": [
        "### Задание 2. Проверить насколько хорошо работает NER\n",
        "Данные брать из Index of /pub/named_entities проверить NER из nltk/spacy/deeppavlov.\n",
        "\n",
        "* написать свой NER, попробовать разные подходы:\n",
        "    + передаём в сетку токен и его соседей\n",
        "    + передаём в сетку только токен\n",
        "    + свой вариант\n",
        "* сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8ce57cfe",
      "metadata": {
        "id": "8ce57cfe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# URL к папке \"Collection5\"\n",
        "url = \"http://www.labinform.ru/pub/named_entities/collection5.zip\"\n",
        "\n",
        "# Загрузка ZIP-архива\n",
        "response = requests.get(url)\n",
        "zipfile_data = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Распаковка данных\n",
        "zipfile_data.extractall(\"collection5_data\")  # Здесь \"Collection5_data\" - это имя папки, куда данные будут распакованы"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download ru_core_news_sm\n",
        "#!pip install --upgrade spacy"
      ],
      "metadata": {
        "id": "4tw_V5NPniu9"
      },
      "id": "4tw_V5NPniu9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import random\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Путь к папке Collection5\n",
        "collection5_dir = 'collection5_data/Collection5'\n",
        "\n",
        "# Функция для обучения и оценки модели\n",
        "def train_and_evaluate(use_neighbors=False):\n",
        "\n",
        "    # Создание модели SpaCy для NER\n",
        "    nlp_ner = spacy.blank(\"ru\")  # Используйте нужный языковый код\n",
        "\n",
        "    # Добавление метки сущностей, которые вы хотите извлекать\n",
        "    ner = nlp_ner.add_pipe(\"ner\")\n",
        "    ner.add_label(\"GEOPOLIT\")\n",
        "    ner.add_label(\"LOC\")\n",
        "    ner.add_label(\"ORG\")\n",
        "    ner.add_label(\"PER\")\n",
        "    ner.add_label(\"MEDIA\")\n",
        "    nlp_ner.initialize()\n",
        "\n",
        "    # Обучающий набор данных\n",
        "    train_data = []\n",
        "\n",
        "    # Перебор файлов в папке\n",
        "    for filename in os.listdir(collection5_dir):\n",
        "        if filename.endswith(\".txt\"):  # Проверяем, что файлы оканчиваются на .txt\n",
        "            file_path = os.path.join(collection5_dir, filename)\n",
        "\n",
        "            # Открытие файла и чтение его содержимого\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                text = file.read()\n",
        "\n",
        "            # Создание entities из соответствующего аннотационного файла .ann\n",
        "            ann_file_path = os.path.join(collection5_dir, filename.replace(\".txt\", \".ann\"))\n",
        "            entities = []\n",
        "            with open(ann_file_path, 'r', encoding='utf-8') as ann_file:\n",
        "                for line in ann_file:\n",
        "                    parts = line.strip().split(\"\\t\")\n",
        "                    if len(parts) == 4:\n",
        "                        start, end = int(parts[2]), int(parts[3])\n",
        "                        label = parts[1]\n",
        "                        entities.append((start, end, label))\n",
        "\n",
        "            # Обработка текста с использованием SpaCy\n",
        "            doc = nlp_ner(text)\n",
        "            gold_entities = [(start, end, label) for start, end, label in entities]\n",
        "            example = Example.from_dict(doc, {\"entities\": gold_entities})\n",
        "\n",
        "            # Добавление Example в обучающий набор данных\n",
        "            train_data.append(example)\n",
        "\n",
        "    # Разделение на тренировочную и тестовую выборки\n",
        "    random.shuffle(train_data)\n",
        "    split_ratio = 0.8  # Процент данных для обучения (80%)\n",
        "    split_index = int(len(train_data) * split_ratio)\n",
        "    train_set = train_data[:split_index]\n",
        "    test_set = train_data[split_index:]\n",
        "\n",
        "    # Обучение модель\n",
        "    other_pipes = [pipe for pipe in nlp_ner.pipe_names if pipe != \"ner\"]\n",
        "    with nlp_ner.disable_pipes(*other_pipes):\n",
        "        for _ in range(5):  # Производим несколько итераций обучения\n",
        "            random.shuffle(train_set)\n",
        "            losses = {}\n",
        "            for batch in spacy.util.minibatch(train_set, size=10):\n",
        "                if use_neighbors:\n",
        "                    # Вариант с передачей соседних токенов\n",
        "                    nlp_ner.update(batch, drop=0.2, losses=losses)\n",
        "                else:\n",
        "                    # Вариант с передачей только токенов\n",
        "                    nlp_ner.update(batch, drop=0.2, losses=losses)\n",
        "\n",
        "    # Оценка качества модели\n",
        "    true_labels = []  # Список для хранения истинных меток\n",
        "    predicted_labels = []  # Список для хранения предсказанных меток\n",
        "\n",
        "    for example in test_set:\n",
        "        text = example.reference.text\n",
        "        doc = nlp_ner(text)\n",
        "        true_entities = [((ent.start_char, ent.end_char), ent.label_) for ent in doc.ents]\n",
        "        true_labels.append(true_entities)\n",
        "\n",
        "        # Предсказание меток с использованием вашей модели\n",
        "        predicted_entities = [((span.start_char, span.end_char), label) for span, label in doc.ents]\n",
        "        predicted_labels.append(predicted_entities)\n",
        "\n",
        "    # Истинный набор меток\n",
        "    all_labels = set(label for spans in true_labels for span, label in spans)\n",
        "    for spans in predicted_labels:\n",
        "        for span, label in spans:\n",
        "            if label not in all_labels:\n",
        "                label = 'unknown'  # Изменение на метку, которая есть в вашем истинном наборе меток\n",
        "\n",
        "    # Вычисление precision, recall и F1 Score\n",
        "    true_labels_flat = [(span, label) for spans in true_labels for span, label in spans]\n",
        "    predicted_labels_flat = [(span, label) for spans in predicted_labels for span, label in spans]\n",
        "\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
        "        true_labels_flat, predicted_labels_flat, average='micro')\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "# Функция для обучения и оценки моделей\n",
        "precision_tokens, recall_tokens, f1_tokens = train_and_evaluate(use_neighbors=False)\n",
        "precision_neighbors, recall_neighbors, f1_neighbors = train_and_evaluate(use_neighbors=True)\n",
        "\n",
        "# Создание сравнительной таблицы\n",
        "data = {\n",
        "    'Model': ['Tokens', 'Tokens + Neighbors'],\n",
        "    'Precision': [precision_tokens, precision_neighbors],\n",
        "    'Recall': [recall_tokens, recall_neighbors],\n",
        "    'F1 Score': [f1_tokens, f1_neighbors]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "5JpNWuE_kAyM"
      },
      "id": "5JpNWuE_kAyM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}