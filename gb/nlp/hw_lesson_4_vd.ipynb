{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a129f53",
   "metadata": {},
   "source": [
    "## Задача тематического моделирования\n",
    "\n",
    "что надо было сделать\n",
    "1. провести исследование и выявить тематики о которых говорят в твитах (для твитов)\n",
    "2. сделать визуализацию кластеров тематик\n",
    "3. проинтерпритировать получившиеся тематики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27f8fe",
   "metadata": {},
   "source": [
    "### Подготовка корпуса данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
    "#!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d571d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем данные из CSV-файлов\n",
    "positive_df = pd.read_csv('positive.csv', sep=';')\n",
    "negative_df = pd.read_csv('negative.csv', sep=';')\n",
    "\n",
    "# Объединяем их в одну выборку\n",
    "combined_df = pd.concat([positive_df, negative_df], axis=0)\n",
    "\n",
    "# Сохраняем объединенный датасет в новый CSV-файл, если необходимо\n",
    "combined_df.to_csv('combined_dataset.csv', index=False)\n",
    "\n",
    "#combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f9fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание полей для исходного датафрейма\n",
    "Field_df = pd.DataFrame()\n",
    "field_template = \"Field_{}\"\n",
    "\n",
    "# Задаем количество полей, которые нужно создать\n",
    "num_fields = combined_df.shape[1]\n",
    "\n",
    "# Создаем столбцы на основе шаблона\n",
    "for i in range(1, num_fields + 1):\n",
    "    field_name = field_template.format(i)\n",
    "    Field_df[field_name] = None  # Здесь можно указать начальные значения для столбцов\n",
    "\n",
    "Field_df = list(Field_df)\n",
    "\n",
    "combined_df.columns = Field_df\n",
    "combined_df = combined_df.astype('str')\n",
    "\n",
    "# Берем только твиты и лейблы\n",
    "combined_df = combined_df[['Field_4', 'Field_5']]\n",
    "\n",
    "new_column_names = ['tweet', 'label']\n",
    "combined_df.columns = new_column_names\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f542a",
   "metadata": {},
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = combined_df\n",
    "selected_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcfa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "# Инициализируйте библиотеки nltk и pymorphy2\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "morph = MorphAnalyzer()\n",
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "\n",
    "# Пример твита\n",
    "tweet = \"Написал код для обработки текстовых данных в Python! #python #NLP\"\n",
    "\n",
    "# Функция для предобработки текста\n",
    "def preprocess_tweet(tweet):\n",
    "    if isinstance(tweet, str):\n",
    "        # Токенизация: разделение текста на слова или токены\n",
    "        words = nltk.word_tokenize(tweet)\n",
    "        \n",
    "        # Приведение к нижнему регистру\n",
    "        words = [word.lower() for word in words]\n",
    "        \n",
    "        # Удаление знаков препинания и цифр\n",
    "        words = [re.sub(r'[^а-яА-Яa-zA-Z]', '', word) for word in words]\n",
    "        \n",
    "        # Удаление стоп-слов\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Лемматизация: приведение слов к их базовой форме\n",
    "        words = [morph.parse(word)[0].normal_form for word in words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "\n",
    "    else:\n",
    "        return words\n",
    "\n",
    "# Применение предобработки к твиту\n",
    "preprocessed_tweet = preprocess_tweet(tweet)\n",
    "print(preprocessed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = selected_columns.dropna(subset=['tweet'])\n",
    "selected_columns['tweet'] = selected_columns['tweet'].astype(str)\n",
    "selected_columns['tweet'] = selected_columns['tweet'].apply(preprocess_tweet)\n",
    "#selected_columns.head(1)\n",
    "selected_columns.to_csv('tweets_for_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f195a8",
   "metadata": {},
   "source": [
    "### Тематическое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cdb724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('tweets_for_analysis.csv')\n",
    "data['tweet'].fillna('', inplace=True)\n",
    "#data.info()\n",
    "\n",
    "# Список стоп-слов на русском языке\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc14657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание мешка слов (Bag of Words)\n",
    "vectorizer = CountVectorizer(max_df=0.8, min_df=2, stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(data['tweet'])\n",
    "\n",
    "# Обучение модели LDA\n",
    "num_topics = 10  # Задайте количество тем\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Вывод топ-слов для каждой темы\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Тема #{topic_idx + 1}: \"\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "n_top_words = 10  # Количество топ-слов для каждой темы\n",
    "print(\"\\nТоп слова для каждой темы:\")\n",
    "print_top_words(lda, vectorizer.get_feature_names_out(), n_top_words)\n",
    "\n",
    "# Визуализация кластеров тематик с помощью t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_representation = tsne.fit_transform(lda.transform(X))\n",
    "\n",
    "# Создание графика\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], c=lda.predict(X), cmap='viridis')\n",
    "plt.title('Визуализация кластеров тематик')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0524ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топ слова для каждой темы:\n",
      "Тема #1: http rt любить ахи ахах свой знать новый ахахи понять\n",
      "Тема #2: завтра написать пойти спать rt писать школа ночь вс идти\n",
      "Тема #3: http rt знать делать думать смотреть любить свой слушать видеть\n",
      "Тема #4: rt http новый привет фильм любить друг нравиться смотреть говорить\n",
      "Тема #5: http rt хороший утро добрый настроение рождение вечер самый дом\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели LDA\n",
    "num_topics = 5  # Количество тем\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Вывод топ-слов для каждой темы\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Тема #{topic_idx + 1}: \"\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "n_top_words = 10  # Количество топ-слов для каждой темы\n",
    "print(\"\\nТоп слова для каждой темы:\")\n",
    "print_top_words(lda, vectorizer.get_feature_names_out(), n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955d0eb",
   "metadata": {},
   "source": [
    "Исходя из топ слов для каждой темы, можно предположить следующие интерпретации:\n",
    "\n",
    "1. **Тема #1: Эмоции и отношения**\n",
    "   - Эта тема может быть связана с выражением эмоций, в том числе радости (ахи, ахах), любви (любить), новых впечатлений (новый), и понимания (понять).\n",
    "\n",
    "2. **Тема #2: Планы и активности**\n",
    "   - В этой теме вероятно рассматриваются различные активности и планы, такие как написание (написать), пойти (пойти), школа (школа), и ночь (ночь).\n",
    "\n",
    "3. **Тема #3: Размышления и восприятие**\n",
    "   - Эта тема может относиться к размышлениям (думать), восприятию (видеть), пониманию (знать), и отношениям (любить, свой).\n",
    "\n",
    "4. **Тема #4: Развлечения и общение**\n",
    "   - Здесь, вероятно, рассматриваются различные развлечения и общение, такие как фильмы (фильм, смотреть), новые знакомства (новый, привет), и общение (говорить).\n",
    "\n",
    "5. **Тема #5: Настроение и время суток**\n",
    "   - Эта тема, возможно, связана с описанием настроения (настроение, хороший, утро, добрый) и различными временами суток (вечер, дом)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b456156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
