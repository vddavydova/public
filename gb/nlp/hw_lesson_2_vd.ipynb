{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUotKHRULVPD"
   },
   "source": [
    "# Инструменты для работы с языком "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ba5Z02VLVPK"
   },
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pdimport numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\AppData\\Local\\Temp\\ipykernel_10280\\3125191635.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = positive.append(negative)\n"
     ]
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZWta7oDgLVP8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for High-Frequency Tokens: 0.7117917790826853\n",
      "Accuracy for Medium-Frequency Tokens: 0.6403216420673967\n",
      "Accuracy for Low-Frequency Tokens: 0.6285245728191292\n"
     ]
    }
   ],
   "source": [
    "# Векторизация текстовых данных\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(x_train)\n",
    "X_test_vec = vectorizer.transform(x_test)\n",
    "\n",
    "# Обучение классификаторов на каждой из групп токенов\n",
    "def train_classifier(tokens, X_train, X_test, y_train, y_test):\n",
    "    # Создание отдельных векторизаторов для каждой группы токенов\n",
    "    vectorizer_tokens = CountVectorizer(vocabulary=tokens)\n",
    "    X_train_tokens = vectorizer_tokens.fit_transform(X_train)\n",
    "    X_test_tokens = vectorizer_tokens.transform(X_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train_tokens, y_train)\n",
    "    y_pred = classifier.predict(X_test_tokens)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return classifier, accuracy\n",
    "\n",
    "# Определение токенов с высокой, средней и низкой частотой\n",
    "token_frequencies = X_train_vec.sum(axis=0).tolist()[0]\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "high_freq_tokens = [feature_names[i] for i, freq in enumerate(token_frequencies) if freq > 100]\n",
    "medium_freq_tokens = [feature_names[i] for i, freq in enumerate(token_frequencies) if 10 < freq <= 100]\n",
    "low_freq_tokens = [feature_names[i] for i, freq in enumerate(token_frequencies) if freq <= 10]\n",
    "\n",
    "classifier_high, accuracy_high = train_classifier(high_freq_tokens, x_train, x_test, y_train, y_test)\n",
    "classifier_medium, accuracy_medium = train_classifier(medium_freq_tokens, x_train, x_test, y_train, y_test)\n",
    "classifier_low, accuracy_low = train_classifier(low_freq_tokens, x_train, x_test, y_train, y_test)\n",
    "\n",
    "print(\"Accuracy for High-Frequency Tokens:\", accuracy_high)\n",
    "print(\"Accuracy for Medium-Frequency Tokens:\", accuracy_medium)\n",
    "print(\"Accuracy for Low-Frequency Tokens:\", accuracy_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features for High-Frequency Tokens:\n",
      "['00lg6bsnb8', '00ngi3vmps', '00okaay', '01цитата', '0vmid1r2qo', '1ajhcakj1y', '03z65obfcx', '1wmcplml4t', '04', '01yqi8ki1v']\n",
      "Significant Features for Medium-Frequency Tokens:\n",
      "['0im3qastxq', '__wwonka', '0rzy39qubw', 'alinaa_bb', '__________', '_want_fly_', '_vvg', '11names', '8qhzotgetz', '0km4cqz3n9']\n",
      "Significant Features for Low-Frequency Tokens:\n",
      "['26uhpe3yl4', 'sun_for', 'seeker_miracle', 'feyastoporom', 'jecye7xzpf', 'emil', 'borskih', 'должностными', 'присранейшего', 'dummukycjv']\n"
     ]
    }
   ],
   "source": [
    "# Получение значимых признаков из классификаторов\n",
    "significant_features_high = [vectorizer.get_feature_names_out()[i] for i in classifier_high.coef_[0].argsort()[-10:][::-1]]\n",
    "significant_features_medium = [vectorizer.get_feature_names_out()[i] for i in classifier_medium.coef_[0].argsort()[-10:][::-1]]\n",
    "significant_features_low = [vectorizer.get_feature_names_out()[i] for i in classifier_low.coef_[0].argsort()[-10:][::-1]]\n",
    "\n",
    "print(\"Significant Features for High-Frequency Tokens:\", significant_features_high, sep='\\n')\n",
    "print(\"Significant Features for Medium-Frequency Tokens:\", significant_features_medium, sep='\\n')\n",
    "print(\"Significant Features for Low-Frequency Tokens:\", significant_features_low, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Count Vectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.77      0.76     28024\n",
      "    positive       0.77      0.76      0.76     28685\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n",
      "Classification Report for TF-IDF Vectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.75     28024\n",
      "    positive       0.75      0.78      0.77     28685\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n",
      "Classification Report for Hashing Vectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.73      0.74     28024\n",
      "    positive       0.75      0.77      0.76     28685\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Векторизация текстовых данных с разными методами\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(x_train)\n",
    "X_test_count = count_vectorizer.transform(x_test)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "hashing_vectorizer = HashingVectorizer()\n",
    "X_train_hashing = hashing_vectorizer.transform(x_train)\n",
    "X_test_hashing = hashing_vectorizer.transform(x_test)\n",
    "\n",
    "# Обучение и оценка моделей\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return report\n",
    "\n",
    "print(\"Classification Report for Count Vectorizer:\")\n",
    "print(train_and_evaluate(X_train_count, X_test_count, y_train, y_test))\n",
    "\n",
    "print(\"Classification Report for TF-IDF Vectorizer:\")\n",
    "print(train_and_evaluate(X_train_tfidf, X_test_tfidf, y_train, y_test))\n",
    "\n",
    "print(\"Classification Report for Hashing Vectorizer:\")\n",
    "print(train_and_evaluate(X_train_hashing, X_test_hashing, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 с проверкой на переобучаемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Count Vectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.76      0.76     16779\n",
      "    positive       0.77      0.76      0.77     17246\n",
      "\n",
      "    accuracy                           0.76     34025\n",
      "   macro avg       0.76      0.76      0.76     34025\n",
      "weighted avg       0.76      0.76      0.76     34025\n",
      "\n",
      "Train Report (for monitoring overfitting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.91     78171\n",
      "    positive       0.91      0.91      0.91     80612\n",
      "\n",
      "    accuracy                           0.91    158783\n",
      "   macro avg       0.91      0.91      0.91    158783\n",
      "weighted avg       0.91      0.91      0.91    158783\n",
      "\n",
      "Classification Report for TF-IDF Vectorizer:\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.75     16779\n",
      "    positive       0.75      0.78      0.77     17246\n",
      "\n",
      "    accuracy                           0.76     34025\n",
      "   macro avg       0.76      0.76      0.76     34025\n",
      "weighted avg       0.76      0.76      0.76     34025\n",
      "\n",
      "Train Report (for monitoring overfitting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84     78171\n",
      "    positive       0.84      0.87      0.85     80612\n",
      "\n",
      "    accuracy                           0.85    158783\n",
      "   macro avg       0.85      0.85      0.85    158783\n",
      "weighted avg       0.85      0.85      0.85    158783\n",
      "\n",
      "Classification Report for Hashing Vectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vddav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.73      0.74     16779\n",
      "    positive       0.75      0.78      0.76     17246\n",
      "\n",
      "    accuracy                           0.75     34025\n",
      "   macro avg       0.75      0.75      0.75     34025\n",
      "weighted avg       0.75      0.75      0.75     34025\n",
      "\n",
      "Train Report (for monitoring overfitting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80     78171\n",
      "    positive       0.80      0.83      0.81     80612\n",
      "\n",
      "    accuracy                           0.81    158783\n",
      "   macro avg       0.81      0.81      0.81    158783\n",
      "weighted avg       0.81      0.81      0.81    158783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на тренировочную, валидационную и тестовую выборки\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df.text, df.label, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Векторизация текстовых данных с разными методами\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_val_count = count_vectorizer.transform(X_val)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "hashing_vectorizer = HashingVectorizer()\n",
    "X_train_hashing = hashing_vectorizer.transform(X_train)\n",
    "X_val_hashing = hashing_vectorizer.transform(X_val)\n",
    "X_test_hashing = hashing_vectorizer.transform(X_test)\n",
    "\n",
    "# Функция для обучения и оценки модели\n",
    "def train_evaluate_report(classifier, X_train, X_val, y_train, y_val):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Оценка на валидационной выборке\n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "    val_report = classification_report(y_val, y_val_pred)\n",
    "    \n",
    "    # Оценка на тренировочной выборке (для мониторинга переобучения)\n",
    "    y_train_pred = classifier.predict(X_train)\n",
    "    train_report = classification_report(y_train, y_train_pred)\n",
    "    \n",
    "    return val_report, train_report\n",
    "\n",
    "# Обучение и оценка моделей с мониторингом переобучения\n",
    "print(\"Classification Report for Count Vectorizer:\")\n",
    "val_report, train_report = train_evaluate_report(LogisticRegression(), X_train_count, X_val_count, y_train, y_val)\n",
    "print(\"Validation Report:\")\n",
    "print(val_report)\n",
    "print(\"Train Report (for monitoring overfitting):\")\n",
    "print(train_report)\n",
    "\n",
    "print(\"Classification Report for TF-IDF Vectorizer:\")\n",
    "val_report, train_report = train_evaluate_report(LogisticRegression(), X_train_tfidf, X_val_tfidf, y_train, y_val)\n",
    "print(\"Validation Report:\")\n",
    "print(val_report)\n",
    "print(\"Train Report (for monitoring overfitting):\")\n",
    "print(train_report)\n",
    "\n",
    "print(\"Classification Report for Hashing Vectorizer:\")\n",
    "val_report, train_report = train_evaluate_report(LogisticRegression(), X_train_hashing, X_val_hashing, y_train, y_val)\n",
    "print(\"Validation Report:\")\n",
    "print(val_report)\n",
    "print(\"Train Report (for monitoring overfitting):\")\n",
    "print(train_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
