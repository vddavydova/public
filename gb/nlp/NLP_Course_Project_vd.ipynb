{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZyeU8qnjAw7"
      },
      "source": [
        "# Bot from GPT to **Telegram**\n",
        "\n",
        "This notebook is the final project for the NLP Сourse at GeekBrains, Faculty of Artificial Intelligence.\n",
        "\n",
        "The notebook contains code for implementing the bot, which is a dialog script. The bot was trained on a dataset of compliments from the Internet, so the ability to receive a random compliment was added at the user’s request."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se6JNcYPjAZd"
      },
      "source": [
        "#!pip install transformers\n",
        "#!pip install python-telegram-bot==13.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpCJfoBgODA"
      },
      "source": [
        "#!wget https://gist.githubusercontent.com/vddavydova/87269a661fc992328a3658468e06d8d1/raw/8befb1e716b84d1cef2397e0c29feb62ebb973ad/compliments.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pathlib\n",
        "\n",
        "from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove\n",
        "from telegram import InlineKeyboardMarkup, InlineKeyboardButton\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext, CallbackQueryHandler\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "oEXvBd_a2G4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia8HOsLMgaua",
        "outputId": "fb987e23-4071-4981-e4af-c28c3744ab0c"
      },
      "source": [
        "# loading training data\n",
        "with open('compliments.txt', 'r') as f:\n",
        "    compliments = f.read().strip().split('\\n')\n",
        "print(len(compliments))\n",
        "for i in range(3):\n",
        "    print(compliments[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325\n",
            "Ты так красива, что я просто не могу отвести взгляд.\n",
            "Твои большие глаза делают тебя такой милой.\n",
            "Ты всегда выглядишь так свежо!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# loading token for bot\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/Colab Notebooks/GPT Week Yandex/data/token-bot.txt')\n",
        "\n",
        "token = [\n",
        "    l for l in open(data_path, 'r').read().split('\\n')\n",
        "    if len(l.strip()) > 0\n",
        "]\n",
        "\n",
        "token = str(token).strip(\"[]'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuqHpsmj2GxZ",
        "outputId": "1725d585-0b53-4813-ad14-aa1dd7839864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading compliments from a file\n",
        "with open('compliments.txt', 'r') as f:\n",
        "    compliments = f.read().strip().split('\\n')\n",
        "\n",
        "# tokenizer and model initialization\n",
        "model_name = 'sberbank-ai/rugpt3large_based_on_gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
      ],
      "metadata": {
        "id": "OESUXK9xw4h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating bot responses\n",
        "def generate_response(text):\n",
        "    prefix = f'\\nx:{text}\\ny:'\n",
        "    tokens = tokenizer(prefix, return_tensors='pt')\n",
        "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
        "    end_token_id = tokenizer.encode('\\n')[0]\n",
        "    size = tokens['input_ids'].shape[1]\n",
        "    output = model.generate(\n",
        "        **tokens,\n",
        "        eos_token_id=end_token_id,\n",
        "        do_sample=True,\n",
        "        max_length=size + 128,\n",
        "        repetition_penalty=3.2,\n",
        "        temperature=1,\n",
        "        num_beams=3,\n",
        "        length_penalty=0.01,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    decoded = tokenizer.decode(output[0])\n",
        "    result = decoded[len(prefix):]\n",
        "    return result.strip()"
      ],
      "metadata": {
        "id": "IAFel4pWVwsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generation of compliments\n",
        "def generate_compliment():\n",
        "    return random.choice(compliments)"
      ],
      "metadata": {
        "id": "c77S4YZIWGkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select a bot response option\n",
        "def respond_to_dialog(update: Update, context: CallbackContext) -> None:\n",
        "    user_input = update.message.text\n",
        "\n",
        "    if \"I want a compliment\" in user_input:\n",
        "        compliment = generate_compliment()\n",
        "        #update.message.reply_text(compliment, reply_markup=ReplyKeyboardRemove())\n",
        "        update.message.reply_text(compliment)\n",
        "\n",
        "    else:\n",
        "        # if not, generate a response using the existing logic\n",
        "        result = generate_response(user_input)\n",
        "        update.message.reply_text(result)"
      ],
      "metadata": {
        "id": "x5oZOsD0WGsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bot implementation\n",
        "def start(update: Update, context: CallbackContext) -> None:\n",
        "    user_id = update.message.from_user.id\n",
        "    keyboard = [['I want a compliment']]\n",
        "    update.message.reply_text('Welcome! Start a dialogue with the bot with any phrase', reply_markup=ReplyKeyboardMarkup(keyboard))\n",
        "\n",
        "def main() -> None:\n",
        "    updater = Updater(token)\n",
        "\n",
        "    dp = updater.dispatcher\n",
        "\n",
        "    dp.add_handler(CommandHandler(\"start\", start))\n",
        "    dp.add_handler(MessageHandler(Filters.text & ~Filters.command, respond_to_dialog))\n",
        "\n",
        "    updater.start_polling()\n",
        "    updater.idle()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "RadE0nwmWGuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXzXRusOpVNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}